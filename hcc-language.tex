To formalize the ideas behind our implementation, we now give a polymorphic 
call-by-name $\lambda$-calculus with algebraic datatypes, pattern matching, and recursion.

\subsection{Syntax and semantics}

Figure~\ref{fig:syntax} presents the details. A program $P$ consists of a set of recursive 
function definitions $f_1^{\ar_1}\ldots f_n^{\ar_n}$ each associated with an {\em arity} $\ar \geq 1$ 
which records the number of explicit abstractions of this function. Each of the function definitions
is of the form $\Lambda\as @.@ \lambda \ol{x{:}\tau} @.@ u$. A term $u$ is either a @case@ expression 
or a @case@-free expression $e$. A @case@-free expression consists of variables $x$, function variables 
$f[\taus]$ fully applied to their type arguments, applications $e_1\;e_2$, data constructor 
applications $K[\taus](\ol{e})$, as well as the special value @BAD@, which will be used to model 
failure as a throwable error term. In what follows we will be treating expressions $e$ as a subset 
of expressions $u$ to save some notation overhead. As a notation, we use $\oln{x}{n}$ for sequences
of elements of size $n$. When $n$ is ommitted $\ol{x}$ has a size which is implied by the context or 
is not interesting.

\begin{figure}
\[\begin{array}{l} 
\begin{array}{lrll}
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Programs}} \\
P   & ::= & @fix@\;(f_1^{\ar_1},...,f_k^{\ar_k})\;@=@ \\ 
    &     & \quad\quad (\Lambda\as_1 @.@ \lambda{\oln{x{:}\tau}{\ar_1}} @.@ u_1,...,
                                                \Lambda\as_k @.@ \lambda{\oln{x{:}\tau}{\ar_k}} @.@ u_k) \\
%% %% d   & ::= & f |-> \Lambda\ol{a} @.@ \lambda\ol{x{:}\tau} @.@ u \\ 
u   & ::= & e \mid @case@\;e\;@of@\;\ol{K\;\ol{y} -> e} \\ 
%%D   & ::= & \cdot \mid D,d \\
\end{array}\\ \\ 
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Expressions}} \\
e  & ::=  & x            & \text{Variables} \\ 
   & \mid & f[\ol{\tau}] & \text{Function variables} \\ 
   & \mid & K[\ol{\tau}](\ol{e}) & \text{Data constructors} \\
   & \mid & e\;e         & \text{Applications} \\
   & \mid & @BAD@        & \text{Runtime error} \\ 
\end{array}\\ \\ 
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Syntax of closed values}} \\
 v,w & ::= & K^\ar[\ol{\tau}](\oln{e}{\ar}) \mid f^\ar[\ol{\tau}]\;\oln{e}{m < \ar} \mid @BAD@ \\ \\ 
\end{array} \\ 
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Contracts}} \\
 \Ct & ::=  & \{ x \mid e \}        & \text{Base contracts}  \\ 
     & \mid &  (x : \Ct_1) -> \Ct_2      & \text{Arrow contracts} \\ 
     & \mid & \Ct_1 \& \Ct_2             & \text{Conjunctions}   \\ 
     & \mid & \CF                        & \text{Crash-freedom}   \\
\end{array}
\end{array}
\end{array}\] 
\caption{Syntax}\label{fig:syntax}
\end{figure}

Our set of definitions encapsulates two constraints: (i)~$\lambda$ abstractions occur only at the 
top-level, and (ii)~@case@-expressions can only immediately follow a function definition. Both 
constructs may not appear arbitrarily deeply nested in expressions $e$. This is not an expressivity 
restriction. In practice the $\lambda$- and @case@- lifting transformation is not uncommon nor 
difficult to support in a compiler. Indeed our prototype relies on existing implementation of 
similar transformations from the GHC-as-a-library GHC API. However using this simpler language 
is instead extremely convenient for the translation of programs to first-order logic.

There are some more non-essential design choices in Figure~\ref{fig:syntax} in order to 
facilitate the formalization and implementation: we assume that data constructors are fully applied 
and functions have arity at least one (disallowing CAF's). 

Furthemore, we assume the existence of a typing relation $\Sigma |- P$, which checks 
that a program conforms to the definitions in the signature $\Sigma$. A signature $\Sigma$ (Figure~\ref{fig:auxiliary-defs})
records the declared data types, data constructors and types of functions in the program $P$. The 
well-formedness of expressions is checked with a typing relation $\Sigma;\Delta |- u : \tau$, where $\Delta$
is a typing environment, also in Figure~\ref{fig:auxiliary-defs}.
We do not give the details of the typing relation since it is standard. An additional property that we require 
from the typing relation is that it {\em asserts the exhaustiveness of pattern matches}. In an {\em actual}
source language programmers may ommit pattern matches but here we will assume that all pattern matches 
are exhaustive. Originally incomplete cases have been completed to return the crashing term @BAD@. For 
instance, the program:
\begin{code}
head :: [a] -> [a]
head (x::xs) = x
\end{code}
will be represented in our language as:
\[\begin{array}{l}
   \Lambda a @.@ \lambda (x{:}[a]) @.@ \\
   \quad @case@\;x\;@of@ \{ [] -> @BAD@ ; (x::xs) -> x \} 
\end{array}\]
Finally, our technical development and analysis in the following sections assume that programs have been 
checked for type errors. 
\begin{figure}
\[\begin{array}{l} 
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Types}} \\
\tau,\sigma & ::=  & T\;\taus & \text{Datatypes} \\ 
            & \mid & a \mid \tau -> \tau 
\end{array}\\ \\ 
%% \begin{array}{lrll}
%% \multicolumn{3}{l}{\text{Datatype declarations}} \\
%% dec & ::= & @data@\;T\;\ol{a} = \ol{K\;\taus}
%% \end{array}\\ \\ 
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Type environments and signatures}} \\
\Gamma & ::=  & \cdot \mid \Gamma,x \\
\Delta & ::=  & \cdot \mid \Delta,a \mid \Delta,x{:}\tau \\
\Sigma & ::=  & \cdot \mid \Sigma,T{:}n \mid \Sigma,f{:}\forall\ol{a} @.@ \tau \mid \Sigma,K^{\ar}{:}\forall\ol{a} @.@ \oln{\tau}{\ar} -> @T@\;\as
\end{array}\\ \\
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Auxiliary functions}} \\
%% constrs(\Sigma,T) & = & \{ K \mid (K{:}\forall \as @.@ \taus -> T\;\as) \in \Sigma \} \\
(\cdot)^{-}            & = & \cdot \\
(\Delta,a)^{-}         & = & \Delta^{-} \\
(\Delta,(x{:}\tau)^{-} & = & \Delta^{-},x
%% \tyar{D}{f} & = & n & \\ 
%%             & \multicolumn{3}{l}{\text{when}\; (f |-> \Lambda\oln{a}{n} @.@ \lambda\ol{x{:}\tau} @.@ u) \in D} \\
%% \tmar{D}{f} & = & n & \\ 
%%             & \multicolumn{3}{l}{\text{when}\; (f |-> \Lambda\ol{a} @.@ \lambda\oln{x{:}\tau}{n} @.@ u) \in D}
\end{array}
\end{array}\]
\caption{Auxiliary definitions}\label{fig:auxiliary-defs}
\end{figure}

Figure~\ref{fig:syntax} also presents the syntax of {\em contracts} to
keep all essential definitions grouped together, but in this section
we will only focus on the language and its semantics. In
Section~\ref{sect:contracts} we return to the syntax and semantics of
contracts.

The syntax of closed values is also given in Figure~\ref{fig:syntax}. Since we do not 
have arbitrary $\lambda$-abstractions, values can only be partial function applications
$f^\ar[\ol{\tau}]\;\oln{e}{m < \ar}$, data constructor applications $K[\tau](\ol{e})$, 
and the error term @BAD@. The evaluation relation that we will be using is given in 
Figure~\ref{fig:opsem} and presents a non-surprising big-step operational semantics. One interesting
detail of big-step semantics is that they do not distinguish between non-termination 
and ``getting stuck'', meaning that if $P \not|- e \Downarrow$ then $e$ could either diverge or its 
evaluation could get stuck. We return to this convenient for our purposes form of operational 
semantics later.

\begin{figure*}
\[\begin{array}{c} 
\ruleform{P |- u \Downarrow v} \\ \\
\prooftree
\begin{array}{c} \ \\ 
\end{array}
-------------------------------------{EVal}
P |- v \Downarrow v
~~~~
\begin{array}{c}
(f |-> \Lambda\ol{a} @.@ \lambda\oln{x{:}\tau}{m} @.@ u) \in P \\
P |- u[\ol{\tau}/\ol{a}][\ol{e}/\ol{x}] \Downarrow v
\end{array}
-------------------------------------{EFun}
P |- f[\ol{\tau}]\;\oln{e}{m} \Downarrow v
~~~~
\begin{array}{c}  
P |- e_1 \Downarrow v_1 \\
P |- v_1\;e_2 \Downarrow w
\end{array}
------------------------------------------------{EApp}
P |- e_1\;e_2 \Downarrow w
~~~~
\begin{array}{c}  
P |- e_1 \Downarrow @BAD@ 
\end{array}
------------------------------------------------{EBadApp}
P |- e_1\;e_2 \Downarrow @BAD@
~~~~~
%% \endprooftree \\ \\ 
%% \ruleform{P |- u \Downarrow v} \\ \\
%% \prooftree
%% P |- e \Downarrow v
%% -------------------------------------{EUTm}
%% P |- e \Downarrow v
%% ~~~~ 
\begin{array}{c}
P |- e \Downarrow K_i[\ol{\sigma}_i](\ol{e}_i) \quad
P |- e'_i[\ol{e}_i/\ol{y}_i] \Downarrow w
\end{array}
------------------------------------{ECase}
P |- @case@\;e\;@of@\;\ol{K\;\ol{y} -> e'} \Downarrow w
~~~~
\begin{array}{c}
P |- e \Downarrow @BAD@ \\
\end{array}
------------------------------------{EBadCase}
P |- @case@\;e\;@of@\;\ol{K\;\ol{y} -> e'} \Downarrow @BAD@
%% \begin{array}{c}
%% (f |-> \Lambda\ol{a} @.@ \lambda\oln{x{:}\tau}{m} @.@ @case@\;e\;@of@\;\ol{K\;\ol{y} -> e'}) \in D \\
%% D |- e[\ol{\tau}/\ol{a}][\ol{e}/\ol{x}] \Downarrow @BAD@ \\
%% \end{array}
%% -------------------------------------{EBadCase}
%% D |- f[\ol{\tau}]\;\oln{e}{m} \Downarrow @BAD@
\endprooftree
\end{array}\]
\caption{Operational semantics}\label{fig:opsem}
\end{figure*}

%% We can state some standard properties of the typing and evaluation relation.
%% \begin{lemma}[Subject reduction]
%% Assume $\Sigma |- P$ and $\Sigma;\cdot |- e : \tau$
%% If $P |- e \Downarrow w$ then $P |- value(w)$ and $\Sigma;\cdot |- w : \tau$.
%% \end{lemma}
Notice that the operational semantics of Figure~\ref{fig:opsem} has the possibility of non-deterministism because
of the overlapping of several rules for applications. But that is not a problem, as we can prove that evaluation 
is deterministic using the following two lemmas.
\begin{lemma}[Value determinacy]
If $\Sigma;\cdot |- v : \tau$ and 
$\Sigma |- P$ and $P |- v \Downarrow w$ then $ v = w $.
\end{lemma}
\begin{lemma}[Determinacy of evaluation]
If $\Sigma;\cdot |- e : \tau$ and 
$\Sigma |- P$ and $\Sigma;\cdot |- e \Downarrow v_1$ and $\Sigma;\cdot |- e \Downarrow v_2$ then
$v_1 = v_2$.
\end{lemma}
Finally, big-step soundness asserts that an expression that evaluates results in a
well-typed value.
\begin{lemma}[Big-step soundness]
If $\Sigma;\cdot |- e : \tau$ and 
$\Sigma |- P$ and $\Sigma;\cdot |- e \Downarrow v$ then $\Sigma;\cdot |- v : \tau$.
\end{lemma}

\subsection{Denotational semantics}\label{ssect:denot}

Having presented the language and its operational semantics, we now return to 
our roadmap which is to axiomatize and use the denotational semantics of programs to 
perform static contract checking. In what follows we will assume a program $P$, 
well-formed in a signature $\Sigma$, so that $\Sigma |- P$. Most of what follows is 
an adaptation of folklore techniques to our setting and there are no 
surprises -- we refer the reader to~\cite{winskel} or~\cite{benton+:coq-domains} 
for a short and modern exposition of the standard methodology.

Given a signature $\Sigma$ we define a strict bi-functor on complete partial 
orders (cpos), below:
%% For a well-formed signature $\Sigma$, we define the strict bi-functor on cpos, below, 
%% assuming that $K_1\ldots K_k$ are all the constructors in $\Sigma$: 
\[\begin{array}{lclll}
  F(D^{-},D^{+}) & = & ( \quad{\prod_{\ar_1}{D^{+}}} & K_1^{\ar_1} \in \Sigma \\
               & + & \;\quad\ldots                    & \ldots \\
               & + & \;\quad{\prod_{\ar_k}{D^{+}}} & K_k^{\ar_k} \in \Sigma \\ 
               & + & \;\quad(D^{-} =>_c D^{+}) \\
               & + & \;\quad\unitcpo_{bad} \quad )_{\bot}
\end{array}\]
The notation $\prod_{n}{D}$ abbreviates $n$-ary products of cpos (the unit cpo $\unitcpo$ if $n = 0$). 
The product and sum constructions are standard, but note that we use the non-strict versions of them. 
The notation $C =>_c D$ denotes the cpo 
induced by the space of continuous functions from the cpo $C$ to the cpo $D$. We use $\unitcpo_{bad}$ 
notation to simply denote a single-element cpo -- the $bad$ subscript is just there for readability. 
The notation $D_\bot$ is {\em lifting}, which is a monad, equipped with the following two continuous 
functions.
\[\begin{array}{l}
   \ret   : D =>_c D_\bot \\ 
   \bind_{f : D =>_c E_\bot} : D_\bot =>_c E_\bot
\end{array}\]
with the obvious definitions. The bi-functor $F$ is the lifting of a big sum: that sum consists of 
(i) products, one for each possible constructor (even accross different data types), (ii) the continuous
function space from $D^{-}$ to $D^{+}$, and (iii) a unit cpo to denote @BAD@ values. 

Observe that we have dropped all type information from the source language. The elements of the products 
corresponding to data constructors are simply $D^{+}$ (instead of more a precise description from type 
information) and the return types of data constructors are similarly ignored. This is not to say that 
a more type-rich denotational semantics is not possible (or desirable even) but this simple denotational 
semantics turns out to be sufficient for formalization and verification. 

%% for $\lambda$-abstractions and @BAD@. Observe that we have 
%% Moreover, the following continuous operations are defined:
%% \[\begin{array}{l} 
%%    \curry_{f : D\times E =>_c F} : D =>_c (E =>_C F) \\ 
%%    \eval : (E =>_c D)\times E =>_c D 
%% \end{array}\] 
%% for any cpos $D, E, F$.

Using the standard {\em embedding-projection} pairs methodology we can show the following.
\begin{lemma}\label{lem:rec-solution} 
There exists a solution to the domain-recursive equation induced by $F$, call it $D_{\infty}$.
Moreover, let a value-domain: $V_{\infty}$ be defined as:
    \[\begin{array}{ll}
             \quad\;{\prod_{\ar_1}{D_{\infty}}} & K_1^{\ar_1} \in \Sigma \\
             \; + \;\ldots                    & \ldots \\
             \; + \;{\prod_{\ar_k}{D_{\infty}}} & K_k^{\ar_k} \in \Sigma \\ 
             \; + \;(D_{\infty} =>_c D_{\infty}) \\
             \; + \;\unitcpo_{bad} \quad
    \end{array}\]
The following continuous functions also exist, each being the inverse of the 
other (i.e. composing to the identity function on the corresponding cpo):
\[\begin{array}{l}
  \roll : (V_{\infty})_\bot =>_c D_{\infty} \\ 
  \unroll : D_{\infty} =>_c (V_{\infty})_\bot
\end{array}\] 
\end{lemma}

%% We summarize the (standard) construction needed for the proof of Lemma~\ref{lem:rec-solution} based on embedding-projection pairs, 
%% because some of its details will be useful later. Consider the chain of cpos $D_i$ defined as: 
%% \[\begin{array}{lcl}
%%    D_0 & = & \{\bot\} \\ 
%%    D_{i+1} & = & F_{\Sigma}(D_i,D_i)
%% \end{array}\]
%% and moreover consider the corresponding {\em embeddings} $e_i : D_i =>_c D_{i+1}$ and 
%% {\em projections} $p_i : D_{i+1} =>_c D_i$ defined as:
%% \[\begin{array}{lcl}
%%    e_0 & = & \dlambda d @.@ \bot_{D_1} \\
%%    p_0 & = & \dlambda d @.@ \bot_{D_0} \\
%%    e_{i+1} & = & F_{\Sigma}(p_i,e_i) \\
%%    p_{i+1} & = & F_{\Sigma}(e_i,p_i)
%% \end{array}\]
%% The following is an easy fact to prove:
%% \begin{lemma}
%% For every $i$ and $x$ element of $D_i$ we have $p_i\cdot e_i(x) = x$. For
%% every $y$ element of $D_{i+1}$ we have that $e_i\ cdot p_i(y) \sqsubseteq y$. 
%% \end{lemma}
%% Consider now the cpo defined by the carrier set 
%%    \[ \{ x \in \Pi_{i \in \omega}D_i \;\mid\; x_n = p_n(x_{n+1}) \} \] 
%% and the pointwise order induced by the order in each $D_i$, and $\bot$ element the 
%% infinite tuple of the corresponding $\bot$ elements. This cpo {\em is} going to be the 
%% set $D_{\infty}$. To prove this we need som more definitions. Let $j_{n,m} : D_n =>_c D_m$ 
%% be defined as:
%% \[\begin{array}{lcl}
%%    j_{n,m}(d) & = & \left\{\begin{array}{ll} 
%%                              e_{m-1}\cdot\ldots \cdot e_n(d) & n < m \\
%%                              d                        & n = m \\
%%                              p_{n-1}\cdot\ldots \cdot p_n(d) & n > m 
%%                           \end{array}\right.
%% \end{array}\]
%% and define $j_i : D_i =>_c D_\infty$ as:
%% \[\begin{array}{lcl}
%%    j_i(d) & = & \langle j_{i,0}(d),j_{i,1}(d),\ldots \\
%% \end{array}\]
%% We can easily show that $j_i$ and $\pi_i$ (the $i$-th projection from a tuple) form
%% an embedding-projection pair:
%% \begin{lemma}
%% For all $i$ and $x$ element of $D_{\infty}$ it is $j_i(\pi_i(x)) \sqsubseteq x$.
%% For all $y$ element of $D_{i}$ it is $\pi_i(j_i(y)) = y$.
%% \end{lemma}
%% The most important theorem is that the limit of $j_i\cdot\pi_i$ is the identity.
%% \begin{lemma}\label{lem:id-sqcup}
%% For all $x$ elements of $D_{\infty}$ it is $\sqcup(j_i\cdot\pi_i)(x) = x$.
%% \end{lemma}
%% \begin{proof} We have one direction by the previous lemma and least upper bounds.
%% So the hard direction is to show that $\sqcup(j_i\cdot\pi_i)(x) \sqsupseteq x$. 
%% We know that:
%% \[       \pi_n(j_n(\pi_n(d))) = \pi_n(d) \]
%% by unfolding definitions and we know that $\sqcup(j_n\cdot\pi_n) \sqsupseteq j_n\cdot\pi_n$
%% since it is a least upper bound. By monotonicity we then get that 
%% \[      \pi_n(\sqcup(j_n\cdot\pi_n)(d)) \sqsupseteq \pi_n(d) \] 
%% but that holds for ever $n$ which means that:
%% \[       \sqcup(j_n\cdot\pi_n)(d) \sqsupseteq d \] 
%% since $\sqsubseteq$ on $D_\infty$ is defined by the conjuction of the 
%% pointwise $\sqsubseteq$ on each $D_i$.
%% \end{proof}
%% Now let us consider the chain 
%% \[ F_{\Sigma}(D_0,D_0) \quad F_{\Sigma}(D_1,D_1) \quad \ldots \] 
%% and the pointed cpo $F_{\Sigma}(D_{\infty},D_{\infty})$ we have that:
%% \[\begin{array}{lcl}
%%     F_{\Sigma}(p_i,e_i)   & : & F(D_i,D_i) =>_c F(D_{i+1},D_{i+1}) \\ 
%%     F_{\Sigma}(\pi_i,j_i) & : & F(D_i,D_i) =>_c F(D_{\infty},D_{\infty})
%% \end{array}\] 
%% we will show that there exists an isomorphism $D_\infty \cong F_{\Sigma}(D_\infty,D_\infty)$.

%% \begin{lemma} Define functions $\roll = \sqcup(j_{i+1}\cdot F_{\Sigma}(j_i,\pi_i))$ and 
%% $\unroll = \sqcup (F_{\Sigma}(\pi_i,j_i)\cdot \pi_{i+1})$. They form the required isomorphism 
%% $D_\infty \cong F_{\Sigma}(D_\infty,D_\infty)$.
%% \end{lemma}
%% This lemma concludes the proof of Lemma~\ref{lem:rec-solution}.

%% The following fact will be extremely useful in establishing the existence of solutions
%% to recursive equations {\em over} the recursively defined domain via approximating the
%% denotations. Let us call $\rho_i = j_i\cdot\pi_i$. 

%% \begin{theorem}\label{lem:min-inv-reqs} The following are true:
%% \begin{itemize} 
%%    \item $\unroll \cdot \rho_{i+1} \cdot \roll = F_{\Sigma}(\rho_i,\rho_i)$ 
%%    \item $\sqcup\rho_i(d) = d$, for all elements $d$ of $D_{\infty}$.
%% \end{itemize}
%% \end{theorem}

\paragraph{Definability of application}
We may now {\em define} application $\dapp : D_\infty \times D_\infty =>_c D_\infty$ as a continuous
function: 
{\setlength{\arraycolsep}{2pt}
\[\begin{array}{rcll}
   \dapp & = & \multicolumn{2}{l}{\dlambda d @.@ \roll(\bind_g (\unroll (\pi_1(d))))} \\
   \text{ where } g & = &  [ & \bot : \prod_{\ar_1}{D_\infty} =>_c D_\infty =>_c (V_\infty)_\bot \\
                    &   &  , & \ldots \\
                    &   &  , & \bot : \prod_{\ar_k}{D_\infty} =>_c D_\infty =>_c (V_\infty)_\bot \\
                    &   &  , & \dlambda d' @.@ \unroll(d'(\pi_2(d))) \\
                    &   &  , & \dlambda b @.@ \dlambda d. \ret(\inj{bad}(b))\hspace{2pt} ] 
\end{array}\]}%
As a notational convention, we have used notation $\langle , \rangle$ to introduce pairs and $[\ldots]$ to 
eliminate ($n$-ary) sums. The projections $\pi_1$ and $\pi_2$ are the obvious continuous projections from the 
binary product space of $D_{\infty}$. We use notation $\inj{K}$ to denote the continuous map that injects some $n$-ary product of $D_{\infty}$ 
corresponding to the arity of constructor $K$ into the sum $V_{\infty}$.
We use notation $\inj{->}$ to denote the continuous injection of $(D_{\infty} =>_c D_{\infty})$ into $V_{\infty}$ and finally, 
$\inj{bad}$ for the unit injection into $V_{\infty}$. We use ordinary application notation $d(d')$ when $d : D_\infty =>_c D_\infty$ and
$d'$ is an element of $D_\infty$. Indeed application, partial application, and currying are all definable in cpos of continuous functions, 
so we will be using $\lambda$-calculus notation for our domain theory, as above. 

In non-technical terms, what does the $\dapp$ combinator express? If the first argument is $\bot$ it will return $\bot$, if the first 
argument is an injection $\inj{bad}$ it will return the same, if it corresponds to a data constructor it will return $\bot$. Finally, 
if the first element is indeed a function, it will apply it. 

\paragraph{Denotational semantics of expressions and programs}

We have now defined the domain-theoretic language and combinators 
that we will use. We proceed to give denotational interpretations of expressions and programs. 

First, the denumerable set of term variable names $x_1,\ldots$ induces a discrete 
cpo $\VarCpo$  and the denumerable set of function variable names $f_1,\ldots$ induces a discrete 
cpo $\FVarCpo$. We define, {\em semantic term environments} to be the cpo $(\VarCpo =>_c D_{\infty})$, 
and {\em semantic function environments} to be the cpo $(\FVarCpo =>_c D_{\infty})$. 

Next we will define $[\![e]\!]$ as a continuous map: 
\[ 
    (\FVarCpo =>_c D_{\infty}) \times (\VarCpo =>_c D_{\infty}) =>_c D_{\infty}
\] 
Below, for a given term $e$ and semantic environments $\rho : \VarCpo =>_c D_{\infty}$ and 
$\sigma : \FVarCpo =>_c D_{\infty}$ we let: 
\[\begin{array}{rcll}
  \interp{x}{\sigma}{\rho} & = & \rho(x) \\ 
  \interp{f\;[\taus]}{\sigma}{\rho} & = & \sigma(f) \\
  \interp{K\;[\taus]\;(\ol{e})}{\sigma}{\rho} & = & \roll(\ret(\inj{K}(\langle\interp{\ol{e}}{\sigma}{\rho}\rangle))) \\ 
  \interp{e_1\;e_2}{\sigma}{\rho} & = & \dapp(\langle \interp{e_1}{\sigma}{\rho}, \interp{e_2}{\sigma}{\rho}\rangle) \\ 
  \interp{@BAD@}{\sigma}{\rho} & = & \roll(\ret(\inj{bad}1))
\end{array}\]
A small technical remark: we write the definition above with pattern matching notation $\langle \sigma,\rho \rangle$ 
(instead of using $\pi_1$ for projecting out $\sigma$ and $\pi_2$ for projecting out $\rho$) but that is fine, 
since $\times$ is not a lifted construction. 

Proceeding in the same way for $[\![u]\!]$ we get:
\[\setlength{\arraycolsep}{2pt}
  \begin{array}{rcll}
  \interp{e}{\sigma}{\rho} & = & \multicolumn{2}{l}{\interp{e}{\sigma}{\rho}} \\ 
  \interp{@case@\;e\;@of@ \ol{ K\;\ys -> e_K}}{\sigma}{\rho} & = & \multicolumn{2}{l}{\roll(\bind_{g} (\unroll(\interp{e}{\sigma}{\rho})))} \\ \\ 
  \text{ where } g  & = & [ & h_{K_1} \\
                    &   & , & \ldots \\
                    &   & , & h_{K_k} \\
                    &   & , & \bot \\ 
                    &   & , & \dlambda b @.@ \ret(b) \hspace{2pt} ] \\ 
              h_{K} & =  & \multicolumn{2}{l}{\dlambda d @.@ \unroll(\interp{e_K}{\sigma}{\rho, \ol{y |-> \pi_i(d)}})} \\ 
                    &   & \multicolumn{2}{l}{\text{when } K \text{ is in the branches}} \\
              h_{K}  & = & \multicolumn{2}{l}{\bot } \\ 
                    &   & \multicolumn{2}{l}{\text{otherwise}}                  
\end{array}\]
A case expression is really translated into a denotational case expression, with the following intuition: For every
constructor that appears in the branches $\ol{K\;\ys -> e_K}$ we eliminate it and return the denotation of the right-hand
side, for the rest of the constructors we simply return $\bot$. Importantly we do {\em not} return $\inj{bad}$ in this 
latter case, as all the missing cases can only be constructors of different datatypes than the datatype that $K$ belongs to. 
As a consequence, returning the ``benign'' value $\bot$ is the right thing to do if we are to ignore completely type errors
in our denotational semantics.

Finally, for a definition $P$ we may define a continuous map:
\[ 
        [\![P]\!] : (\FVarCpo =>_c D_{\infty}) =>_c (\FVarCpo =>_c D_{\infty}) 
\]
Let $P$ be 
\[\begin{array}{l} 
     @fix@\;(f_1^{\ar_1},...,f_k^{\ar_k})\;@=@\; 
     (\lambda{\oln{x{:}\tau}{\ar_1}} @.@ u_1,...,
                   \Lambda\as_k @.@ \lambda{\oln{x{:}\tau}{\ar_k}} @.@ u_k) 
\end{array}\] 
Then
\[\begin{array}{l}  
   [\![P]\!]_{\sigma} f =  \\ 
     \qquad\text{ if } (f |-> \Lambda\as @.@ \lambda\oln{x:\tau}{n} @.@ u) \in P \\
     \qquad\text{ then } \\
     \qquad\quad\quad \roll(\ret(\inj{->}(\dlambda d_1 @.@ \ldots  \\
     \qquad\quad\quad\quad \roll(\ret(\inj{->}(\dlambda d_n @.@ \interp{u}{\sigma}{\ol{x |-> d}})))\ldots))) \\
     \qquad \text{ else } \bot
\end{array}\]

Since $[\![P]\!]$ is continuous, its limit exists and is an element of the 
cpo $\FVarCpo =>_c D_{\infty}$.


\begin{definition}
We will refer to the limit of the $\dbrace{P}$ as $\dbrace{P}^{\infty}$ in what follows. 
Moreover, to reduce notational overhead below, for a program with no free variables we 
will use notation $\dbrace{e}$ to mean $\interp{e}{\dbrace{P}^\infty}{\cdot}$.
\end{definition}

Types do not matter at all for our denotational semantics.
\begin{lemma}[Type irrelevance]
It is the case that $\interp{u}{\sigma}{\rho} = \interp{u[\ol{\tau}/\as]}{\sigma}{\rho}$ 
for any type substitution of variable $\as$ to types $\taus$.
%% and $\interp{e}{\sigma}{\rho} = \interp{e[\ol{\tau}/\as]}{\sigma}{\rho}$.
\end{lemma}
%% \begin{proof} Straightforward induction. \end{proof}
The following is an essential lemma for establishing the soundness of denotational semantics:
\begin{lemma}[Substitutivity]
If $\Sigma;\Delta,x{:}\tau |- e : \tau$ and $\rho$ is a semantic environment 
and $\Sigma;\Delta |- e' : \tau'$ then 
\[ \interp{e}{\sigma}{\rho,x |-> \interp{e'}{\sigma}{\rho}} = \interp{e[e'/x]}{\sigma}{\rho} \]
and if $\Sigma;\Delta,x{:}\tau |- u : \tau$ then 
\[ \interp{u}{\sigma}{\rho,x |-> \interp{e'}{\sigma}{\rho}} = \interp{u[e'/x]}{\sigma}{\rho} \]
\end{lemma}
Finally, soundness asserts that evaluation respects the denotational semantics.\footnote{Depending on their taste
readers may prefer to read this statement as: denotational semantics respects evaluation.}
\begin{lemma}[Denotational semantics soundness]
Assume $\Sigma |- P$ and $u$ with no free term variables. If $P |- u \Downarrow v$ then $\dbrace{u} = \dbrace{v} $.
\end{lemma} 
Finally we are interested in proving the following theorem
\begin{theorem}[Computational adequacy]\label{thm:adequacy}
Assume that $\Sigma |- P$ and $e$ contains no free term variables.
If $\unroll(\dbrace{e}) = \ret(d)$ for some element $d$ of $V_{\infty}$, then 
there exists a $v$ such that $P |- e \Downarrow v$.
\end{theorem}

The proof of this theorem is also standard domain theory so we only sketch the 
high-level roadmap: The proof proceeds by defining a {\em logical relation} between 
semantics and syntax, via the use of a bifunctor on admissible relations between elements 
of $D_\infty$ and closed expressions, and using minimal 
invariance~\cite{pitts-rel-domains} to show that this
bifunctor has a fixpoint. Adequacy then follows from the {\em fundamental theorem} of this 
logical relation, which asserts that every expression is related to its denotation.

%% To do this we define a {\em logical relation} first between semantics 
%% and syntax. Let $Rel \subseteq D_\infty \times Expr$ be the space of 
%% {\em admissible} and {\em equality-respecting} relations between 
%% denotations and closed (non-necessarily well-typed) terms. Some explanations:
%% \begin{itemize}
%%   \item $R \in Rel$ is {\em admissible} iff whenever 
%%   $R(d_i,e)$ for every element of a chain $d_1\ldots$ then also $R(\sqcup_{\omega}d_i,e)$. 
%%   \item $R \in Rel$ is {\em equality-respecting} iff for every 
%%   $R(d,e)$ and $d' = d$ (according to the equality on $D_{\infty}$) it also is
%%   $R(d',e)$. 
%% \end{itemize}

%% Let use define the following bi-functor on the space of $Rel$ relations:
%% {\setlength{\arraycolsep}{2pt}
%% \[\begin{array}{lcl}
%%    F_{P}(R^{-},R^{+}) & = & \{ (d,e)\;\mid\;\forall \ol{d} @.@ \unroll(d) = \ret(\inj{K_1^\ar}\langle\oln{d}{\ar}\rangle) ==> \\
%%                    &   & \quad \exists \oln{e}{\ar} @.@ P |- e \Downarrow K_1[\taus](\ol{e}) \land (d_i,e_i) \in R^{+} \} \\ 
%%                    & \cup & \ldots \\ 
%%                    & \cup & \{ (d,e)\;\mid\;\forall d_0 @.@ \unroll(d) = \ret(\inj{->}(d_0)) ==> \\ 
%%                    &   & \quad \exists v @.@ P |- e \Downarrow v \;\land \\ 
%%                    &  & \quad\quad \forall (d',e') \in R^{-} @.@ (\dapp(d,d'),v\;e') \in R^{+} \}  \\
%%                    & \cup & \{ (d,e)\;\mid\; \unroll(d) = \ret(\inj{bad}(1)) ==> \\ 
%%                    &   & \quad P |- e \Downarrow @BAD@ \} 
%% \end{array}\]}

%% \begin{lemma} There exists negative and a positive fixpoint of $F_{P}$ and they coincide: let us call this
%% $F_{P}^\infty$ -- it is isomorphic to $F_{P}(F_P^\infty,F_P^\infty)$.
%% \end{lemma}
%% \begin{proof}
%% We can follow the standard roadmap described in the work of Pitts to show this, taking 
%% advantage of the approximation on every element of $D_{\infty}$ given in 
%% Lemma~\ref{lem:min-inv-reqs}.
%% \end{proof}

%% \begin{lemma}\label{lem:bot-in-fix}
%% $(\roll(\bot),e) \in F_{P}^\infty$. \end{lemma}

%% \begin{lemma}\label{lem:eval-respecting}
%% If $(d,e) \in F_{P}^\infty$ and $P |- e \Downarrow v$ then $(d,v) \in F_{P}^\infty$.
%% Moreover, if $(d,v) \in F_{P}^\infty$ and $P |- e \Downarrow v$ then $(d,e) \in F_{P}^\infty$.
%% \end{lemma}
%% \begin{proof}
%% For the first part, 
%% if $(d,e) \in F_{P}^\infty$ then $(d,e) \in F_{P}(F_{P}^\infty,F_{P}^\infty)$. 
%% By the definition of $F_{P}(\cdot,\cdot)$ and by rule \rulename{EVal} the 
%% result follows. The second part is a similar case analysis.
%% \end{proof}

%% \begin{lemma}[Fundamental theorem for expressions]\label{lem:fund-thm-exp}
%% For all $\sigma$ such that $(\sigma(f),f\;[\taus]) \in F_P^\infty$ and 
%% all $\rho$ and vectors of closed terms $\ol{e}$ such that $(\rho(x_i),e_i) \in F_P^\infty$ 
%% and all $e$ with free variables in $\ol{x}$ it must be the case 
%% that $(\interp{e}{\sigma}{\rho},e[\ol{e}/\ol{x}]) \in F_P^\infty$.
%% \end{lemma}
%% \begin{proof} The proof is by induction on $e$. 
%% \begin{itemize}
%%   \item Case $e = x_i$ for some $x_i \in \ol{x}$ follows by the assumptions.
%%   \item Case $e = f\;[\taus]$ for some $f$ follows by assumptions.
%%   \item Case $e = K^\ar[\taus](\oln{e'}{\ar})$. By induction hypothesis we 
%%   have that for each $e'_i$ it is $(\interp{e'_i}{\sigma}{\rho},e'_i[\ol{e}/\ol{x}]) \in F_P^\infty$ and 
%%   by using rule \rulename{EVal} we are done since 
%%       \[ \interp{K^{\ar}[\taus](\oln{e'}{\ar})}{\sigma}{\rho} = \roll(\ret(\inj{K}(\langle\ol{\interp{e'_i}{\sigma}{\rho}}\rangle))) \]
%%   \item Case $e = @BAD@$ follows by unfolding definitions.
%%   \item Case $e = e_1\;e_2$. We need to show that
%%      \[ (\interp{e_1\;e_2}{\sigma}{\rho},e_1[\ol{e}/\ol{x}]\;e_2[\ol{e}/\ol{x}]) \in F_P^\infty \] 
%%   By induction hypothesis we have that 
%%   \begin{eqnarray}
%%      (\interp{e_1}{\sigma}{\rho},e_1[\ol{e}/\ol{x}]) \in F_P^\infty \label{eqn:e1} \\ 
%%      (\interp{e_2}{\sigma}{\rho},e_2[\ol{e}/\ol{x}]) \in F_P^\infty \label{eqn:e2}
%%   \end{eqnarray}
%%   Equation~\ref{eqn:e1} gives four cases: First, if $\interp{e_1}{\sigma}{\rho} = \roll(\bot)$ then we 
%%   are done since $\dapp(\bot,\_) = \roll(\bot)$ and $(\roll(\bot), e_1\;e_2) \in F_P^\infty$ by Lemma~\ref{lem:bot-in-fix}.
%%   Second, if $\interp{e_1}{\sigma}{\rho} = \roll(\ret(\inj{K}(\langle\ol{d}\rangle)))$ for some constructor
%%   $K$ then $\dapp(\interp{e_1}{\sigma}{\rho},\_) = \roll(\bot)$ and by similar reasoning as above we are done.
%%   Third, if $\interp{e_1}{\sigma}{\rho} = \roll(\ret(\inj{bad}(1)))$ then it must be that $P |- e_1[\ol{e}/\ol{x}] \Downarrow @BAD@$ by
%%   induction hypothesis, and by rule \rulename{EBadApp} we know that $P |- e_1[\ol{e}/\ol{x}]\;e_2[\ol{e}/\ol{x}] \Downarrow @BAD@$ hence, 
%%   by Lemma~\ref{lem:eval-respecting} we are done. The final case is the interesting one, where
%%   $\interp{e_1}{\sigma}{\rho} = \roll(\ret(\inj{->}(d_0)))$ in which case by induction hypothesis we know that 
%%   $(d_0(\interp{e_2}{\sigma}{\rho}), v\;e_2[\ol{e}/\ol{x}]) \in F_P^\infty$ for $P |- e_1[\ol{e}/\ol{x}] \Downarrow v$. But we know that 
%%   $v\;e_2[\ol{e}/\ol{x}]$ evaluates to a value {\em iff} $e_1[\ol{e}/\ol{x}]\;e_2[\ol{e}/\ol{x}]$ evaluates to a value and by 
%%   Lemma~\ref{lem:eval-respecting} we are done.
%% \end{itemize}
%% \end{proof}


%% \begin{lemma}[Fundamental theorem for top-level expressions]\label{lem:fund-thm-case}
%% For all $\sigma$ such that $(\sigma(f),f\;[\taus]) \in F_P^\infty$ and 
%% all $\rho$ and vectors of closed terms $\ol{e}$ such that $(\rho(x_i),e_i) \in F_P^\infty$ 
%% and all $u$ with free variables in $\ol{x}$ it must be the case 
%% that $(\interp{u}{\sigma}{\rho},u[\ol{e}/\ol{x}]) \in F_P^\infty$.
%% \end{lemma}
%% \begin{proof} By induction on $u$. If $u$ is a term $e$ then we are immediately done
%% by Lemma~\ref{lem:fund-thm-exp}. If $u = @case@\;e\;@of@\;\ol{K\;\ys -> e'}$ then the 
%% result follows by appealing to the induction hypothesis for $e$ and performing a case 
%% analysis on $\interp{e}{\sigma}{\rho}$ -- in the interesting case we appeal further to
%% Lemma~\ref{lem:fund-thm-exp} for a matching $e_K$ and the evaluation-respecting lemma, 
%% Lemma~\ref{lem:eval-respecting}.
%% \end{proof}

%% Finally, for the recursive functions environment $P$ we prove the following.
%% \begin{lemma} For any $f$, $(\dbrace{P}^\infty(f),f\;[\taus]) \in F_P^\infty$. \end{lemma}
%% \begin{proof}
%% Since $F_P^\infty$ is itself an {\em admissible} relation, we need only prove that:
%% \[ \forall i @.@ \forall f @.@ (\dbrace{P}^i(f),f\;[\taus]) \in F_P^\infty \] 
%% which we do by induction on $i$. For $i = 0$ we are immediately done by Lemma~\ref{lem:bot-in-fix}.
%% Let us assume that the property is true for $i$. We must show it is true for $i+1$. That is, 
%% we must show that $(\dbrace{P}^{i+1}(f),f\;[\taus]) \in F_P^\infty$. Hence, if $f$ has arity $n$, by
%% the definition of $\dbrace{P}$ and the definition of the logical relation it is enough to show that
%% for all $(\oln{d}{n},\oln{e}{n}) \in F_P^\infty$ it must be the case that 
%% \[    (\interp{u}{\dbrace{P}^i}{\ol{x |-> d}}, u[\ol{e}/\ol{x}]) \in F_P^\infty \] 
%% for $f |-> (\Lambda\as @.@ \lambda\oln{x{:}\tau}{n} @.@ u) \in P$. But that follows by 
%% Lemma~\ref{lem:fund-thm-case}, since by induction hypothesis it is the case that for 
%% every $f$ we have $(\dbrace{P}^i(f),f\;[\ol{\tau}]) \in F_P^\infty$.
%% \end{proof} 

%% \begin{corollary}\label{cor:fund-thm-top}
%% For every closed expression $e$ in $P$ (not-necessarily well-typed) we have that 
%% $(\interp{e}{\dbrace{P}^\infty}{\cdot}, e) \in F_P^\infty$. 
%% \end{corollary}

%% From this corollary, adequacy follows by unfolding definitions.

%% \begin{corollary}[Model-based-reasoning]
%% If $\Sigma |- P$ and and $e_1$ contains no free term variables and $e_2$ contains no free term 
%% variables. 

%% $\Sigma;\cdot |- e_1 : \tau$ and $\Sigma;\cdot |- e_2 : \tau$, 
%% then for every closed $e$ such that $\Sigma |- P$ and $\Sigma;\cdot |- e : \tau -> Bool$,
%% if $\interp{e_1}{\dbrace{P}^\infty}{\cdot} = \interp{e_2}{\dbrace{P}^\infty}{\cdot}$ then  
%% $P |- e\;e_1 \Downarrow$ iff $P |- e\;e_2 \Downarrow$. 
%% \end{corollary}
%% \begin{proof}
%% For one direction assume that $P |- e\;e_1 \Downarrow w$, hence by computational soundness it must be that 
%% $\interp{e\;e_1}{\dbrace{P}^\infty}{\cdot} = \roll(\ret(d))$. By assumptions we must also 
%% have that $\interp{e\;e_2}{\dbrace{P}^\infty}{\cdot} = \roll(\ret(d))$. By the fundamental theorem 
%% we know that 
%% \[ (\interp{e\;e_2}{\dbrace{P}^\infty}{\cdot}, e\;e_2) \in F_{P}^\infty \] 
%% and hence $P |- e\;e_2 \Downarrow$. The other direction is symmetric.
%% \end{proof}

\subsection{Denotational semantics in first-order logic}\label{ssect:denot-fol}

Recall our plan: we wish to translate programs and contracts to first-order logic
so that we can prove that programs satisfy their contracts. We start by formally 
defining the first-order language which will be the image of our translation. 

This syntax is given in Figure~\ref{fig:fol-image}. Terms include function 
applications $f(\ol{t})$, constructor applications $K(\ol{t})$, variables. They 
also include, for each data constructor $K^\ar$ in the signature $\Sigma$ with 
arity $\ar$ a set of {\em selector functions} $\sel{K}{i}(t)$ for $i \in 1 \ldots \ar$.
Not all functions are fully applied, so to accommodate partial applications, we use 
the term $app(t,s)$. Functions that are not applied, but rather passed on as essentially 
function pointers will be represented as variables (or nullary functions) $f_{ptr}$. Finally 
we introduce two new syntactic constructs $\unr$ and $\bad$. As an abreviation we often use
$app(t,\ol{s})$ for the sequence of applications to each $s_i$, as 
Figure~\ref{fig:fol-image} shows.

\begin{figure}
\[\begin{array}{c} 
\begin{array}{lrll}
\multicolumn{3}{l}{\text{Terms}} \\
  s,t & ::=  & x                          & \text{Variables} \\ 
      &      & f(\ol{t})                  & \text{Functions} \\
      &      & K(\ol{t})                  & \text{Constructor functions} \\ 
      & \mid & \sel{K}{i}(t)              & \text{Constructor selectors} \\ 
      & \mid & f_{ptr} \mid app(t,s)       & \text{Pointers and application} \\
      & \mid & \unr \mid \bad             & \text{Unreachable, bad} \\ \\
\multicolumn{3}{l}{\text{Formulae}} \\ 
 \phi & ::=  & \lcf{t}    & \text{Crash-freedom} \\
%%      & \mid & \lncf{t}   & \text{Can provably cause crash} \\
      & \mid & t_1 = t_2  & \text{Equality} \\ 
      & \mid & \phi \land \phi \mid \phi \lor \phi \mid \neg \phi \\
      & \mid & \forall x @.@ \phi \mid \exists x @.@ \phi \\ \\ 
\multicolumn{3}{l}{\text{Abbreviation}} \\ 
\multicolumn{4}{l}{app(t,\oln{s}{n}) = (\ldots(app(t,s_1),\ldots s_n)\ldots)}
\end{array}
\end{array}\]
\caption{Image of translation to FOL}\label{fig:fol-image}
\end{figure}

To group interesting definitions together, Figure~\ref{fig:fol-image}
also includes the syntax of formulae that will appear in our translation.
It is just first-order logic with equality, plus a predicate $\lcf{t}$ for 
crash-freedom, whose semantics we discuss in Section~\ref{sect:contracts}.


\begin{figure}\small
\[\begin{array}{c} 
\ruleform{\etrans{\Sigma}{\Gamma}{e} = \formula{t} } \\ \\
\prooftree
  \begin{array}{c}
  (f{:}\forall\oln{a}{n} @.@ \tau) \in \Sigma
  \end{array}
  --------------------------------------{TFVar}
  \etrans{\Sigma}{\Gamma}{f[\oln{\tau}{n}]} = \formula{f_{ptr}}
  ~~~~ 
  x \in \Gamma 
  --------------------------------------{TVar}
  \etrans{\Sigma}{\Gamma}{x} = \formula{x}
  ~~~~~ 
  \begin{array}{c}
  (K{:}\forall\oln{a}{n} @.@ \ol{\tau} -> T\;\as) \in \Sigma \quad
  \ol{\etrans{\Sigma}{\Gamma}{e} = \formula{t}}
  \end{array}
  --------------------------------------{TCon}
  \etrans{\Sigma}{\Gamma}{K[\oln{\tau}{n}](\ol{e})} = \formula{K(\ol{t})}
  ~~~~~
  \phantom{\Gamma}
  --------------------------------------{TBad}
  \etrans{\Sigma}{\Gamma}{@BAD@} = \formula{\bad}
  ~~~~
  \begin{array}{c}
  \etrans{\Sigma}{\Gamma}{e_1} = \formula{t_1} \\
  \etrans{\Sigma}{\Gamma}{e_2} = \formula{t_2}
  \end{array}
  --------------------------------------{TApp}
  \etrans{\Sigma}{\Gamma}{e_1\;e_2} = \formula{app(t_1,t_2)}
\endprooftree \\ \\ 
\ruleform{\utrans{\Sigma}{\Gamma}{t \sim u} = \formula{\phi}} \\ \\ 
\prooftree
   \etrans{\Sigma}{\Gamma}{e} = \formula{t}
   ----------------------------------------{DExp}
   \utrans{\Sigma}{\Gamma}{s \sim e } = \formula{s = t} 
   ~~~~~
  \begin{array}{l}
  \etrans{\Sigma}{\Gamma}{e} = \formula{t} \\
%%  constrs(\Sigma,T) = \ol{K} \\
  \text{for each branch}\;(K\;\oln{y}{l} -> e') \text{ it is } \etrans{\Sigma}{\Gamma,\ol{y}}{e'} = \formula{ t_K }
%%  \begin{array}{l}
%% %%           (K{:}\forall \cs @.@ \oln{\sigma}{l} -> T\;\oln{c}{k}) \in \Sigma \text{ and }
%%            \etrans{\Sigma}{\Gamma,\ol{y}}{e'} = \formula{ t_K }
%%   \end{array}
  \end{array}
  ------------------------------------------{DCase}
  {  \setlength{\arraycolsep}{2pt} 
  \begin{array}{l}
  \utrans{\Sigma}{\Gamma}{s \sim @case@\;e\;@of@\;\ol{K\;\ol{y} -> e'}} = \\
  \;\;\formula{ \begin{array}{l} 
          (t = \bad => s = bad)\;\land \\ 
          (\forall \ol{y} @.@ t = K_1(\ol{y}) => s = t_{K_1}\;\land \ldots \land \\
          (t{\neq}\bad\;\land\;t{\neq}K_1(\oln{{\sel{K_1}{i}}(t)}{})\;\land\;\ldots => s{=}\unr) 
%% (t = \bad /\ s = \bad)\;\lor\;(s = \unr)\;\lor \\
%%                                 \quad      \bigvee(t = K(\oln{{\sel{K}{i}}(t)}{}) \land
%%                                            s = t_K[\oln{\sel{K}{i}(t)}{}/\ol{y}])
                   \end{array}
           }
  \end{array}}
\endprooftree \\ \\ 
\ruleform{ \Dtrans{\Sigma}{P} = \formula{\phi}} \\ \\ 
\prooftree
     \begin{array}{l}       
       \text{for each} (f |-> \Lambda\oln{a}{n} @.@ \lambda\oln{x{:}\tau}{m} @.@ u) \in P \\ 
          \quad \utrans{\Sigma}{\ol{x}}{f(\ol{x}) \sim u} = \formula{\phi}
     \end{array}
     --------------------{TDefs}
     \Dtrans{\Sigma}{P} = \bigwedge_{P} \formula{\forall \ol{x} @.@ \phi}
\endprooftree 

\end{array}\]
\caption{Translation to FOL terms}\label{fig:etrans}
\end{figure}

\paragraph{Translation of expressions to FOL}

The translation of expressions $e$ which may contain term variables from $\Gamma$ to 
first-order logic terms is given in Figure~\ref{fig:etrans} with the function
$\etrans{}{\Gamma}{e}$. Variables map to variables, functions map to function pointers, 
applications map to applications of $app(\cdot,\cdot)$, constructors map to constructor
function applications and @BAD@ maps to $\bad$.

It is now time to give an interpretation to our FOL terms. Our idea is to use the 
denotational semantics domain $D_\infty$ {\em itself} as the carrier set of the model. 
We then need to give an interpretation of the functions and constants in our first-order
signature as elements of $D_\infty$. Happily this is straightforward to do:
\[\begin{array}{rcl}
   \linterp{f^{\ar}}(d_1,\ldots,d_\ar) & = & \dapp(\dbrace{f},\oln{d}{\ar}) \\ 
   \linterp{app}(d_1,d_2)     & = & \dapp(d_1,d_2) \\
   \linterp{f_{ptr}}  & = & \dbrace{f} \\
   \linterp{K^{\ar}}(d_1,\ldots,d_\ar) & = & \roll(\ret(\inj{K}\langle d_1,\ldots,d_\ar\rangle)) \\ 
   \linterp{\sel{K}{i}}(d) & = &  \roll(\bind_g(\unroll(d))) \\ 
     \text{where } g  & = & [\;\bot \\ 
                      &   & ,\;\dlambda d @.@ \unroll(\pi_i(d))  \quad (\text{case for K}) \\ 
                      &   & ,\;\bot \\
                      &   & ,\;\ldots\\
                      &   & ,\;\bot\; ] \\
  \linterp{unr}       & = & \bot 
\end{array}\]
The essential soundness theorem that states that our interpretation makes sense is
the following. 
\begin{theorem}[Interpretation respects denotations] 
Assume that $\Sigma |- P$ and expression $e$ does not contain any free variables. 
Then, if $\etrans{}{\cdot}{e} = t$ then $\linterp{t} = \dbrace{e}$.
\end{theorem}
The proof is an easy induction on the size of the term $e$.

\paragraph{Translation of programs and {\tt case} expressions}
A program $P$ is translated to a first order logic formula with the function 
$\dtrans{}{P}$. For each function definition of a function $f^\ar$ we generate
a quantified formula $\forall \xs @.@ \utrans{}{\ol{x}}{f(\ol{x}) \sim u}$ where $u$ is the 
right-hand side of the definition of $f$ in $P$. The function 
$\utrans{}{\Gamma}{t \sim u}$ generates the necessary formula to equate the left-hand-side
first-order term $t$ to a term corresponding to $u$. The context $\Gamma$ is present
for book-keeping purposes. As Figure~\ref{fig:etrans} shows there are two cases to 
consider. If $u$ is just a @case@-free expression $e$, in which case we generate
an equality formula (rule \rulename{DExp}. 

The most interesting rule is \rulename{DCase}. If the translation of the scrutinee
$t$ is equal to $\bad$ then the left-hand-side $s$ must be equal to $\bad$. If it is 
equal to some constructor application from the case expressions then the right 
hand-side is equal to the corresponding translation $t_K$ of some pattern branch. Finally
if the scrutinee is not $\bad$ nor some of the constructors in the branch we assert that
the left-hand-side $s$ must be equal to $\unr$. The rule precisely corresponds to our 
intuitions from the denotational semantics: in the denotational semantics, whenever
we attempt to scrutinize a constructor of a different type in a case expression, the 
resulting denotation is simply $\bot$. This reinforces our desire to treat type errors
as $\bot$ values. 

Indeed the denotational domain $D_\infty$ along with the interpretation 
${\cal I}$ constitutes a model of the formulae generated by $\dtrans{}{P}$. 

\begin{theorem}
If $\Sigma |- P$ then $\langle D_{\infty},{\cal I}\rangle \models \dtrans{\Sigma}{P}$. 
\end{theorem}

\paragraph{Axiomatization of denotational semantics}

We have seen that the interpretations of the FOL representations of terms 
correspond precisely to the denotational semantics of terms. In order to be able to 
prove properties about these denotations in first-order logic we had better
axiomatize some of the useful properties of $D_\infty$.

Figure~\ref{fig:prelude} gives an axiomatization. For notational convenience the reader
should think that each of these rules can potentially give a conjunction of formulae.
The axiom \rulename{AxDisjBU} asserts that $\bad$ cannot be equated to $\unr$. 
Rule \rulename{AxDisjC} is really givin a conjunction of axioms. It asserts that all 
constructors are disjoint with each other and \rulename{AxDisjCBU} asserts that they 
are also disjoint from $\bad$ and $\unr$. 
Axiom group \rulename{AxPtr} asserts that full applications of function pointers 
are equal to the actual function applications and \rulename{AxApp} describes the behavior
of $app(\cdot,\cdot)$ when the first argument is $\bad$ or $\unr$. Finally the selector
functions describe how we can project a value out of a datatype. 

\begin{figure}
\[\begin{array}{c}
\ruleform{\Th_\infty} \\ \\ 
{\setlength{\arraycolsep}{2pt}
\begin{array}{lll} 
 \textsc{AxDisjBU} & \formula{\bad \neq \unr}  \\ 
 \textsc{AxDisjC} & \formula{\forall \oln{x}{n}\oln{y}{m} @.@ K(\ol{x}) \neq J(\ol{y})} \\ 
                  & \text{ for every } (K{:}\forall\as @.@ \oln{\tau}{n} -> T\;\as) \in \Sigma \\ 
                  & \text{ and } (J{:}\forall\as @.@ \oln{\tau}{m} -> S\;\as) \in \Sigma \\
 \textsc{AxDisjCBU} & \formula{(\forall \oln{x}{n} @.@ K(\ol{x}) \neq \unr \land K(\ol{x}) \neq \bad)} \\ 
                  & \text{ for every } (K{:}\forall\as @.@ \oln{\tau}{n} -> T\;\as) \in \Sigma \\ \\
 \textsc{AxPtr}  & \formula{\forall \oln{x}{n} @.@ f(\ol{x}) = app(f_{ptr},\xs)} \\
               & \text{ for every } (f |-> \Lambda\as @.@ \lambda\oln{x{:}\tau}{n} @.@ u) \in P \\
 %% \textsc{AxAppB}  & \formula{\forall \oln{x}{n} @.@ K(\ol{x}) = app(\ldots (app(x_K,x_1),\ldots,x_n)\ldots)} \\
 %%                  & \text{ for every } (K{:}\forall\as @.@ \oln{\tau}{n} -> T\;\as) \in \Sigma \\
 \textsc{AxApp}  & \formula{\forall x @.@ app(\bad,x){=}\bad /\ app(\unr,x){=}\unr}    \\ \\
 %% Not needed: we can always extend partial constructor applications to fully saturated and use AxAppC and AxDisjC
 %% \textsc{AxPartA} & \formula{\forall \oln{x}{n} @.@ app(\ldots (app(x_K,x_1),\ldots,x_n)\ldots) \neq \unr} \\
 %%                  & \formula{\quad\quad \land\; app(\ldots (app(x_K,x_1),\ldots,x_n)\ldots) \neq \bad} \\
 %%                  & \text{ for every } (K{:}\forall\as @.@ \oln{\tau}{m} -> T\;\as) \in \Sigma \text{ and } m > n \\
 \textsc{AxInj}   & \formula{\forall \oln{y}{n} @.@ \sel{K}{i}(K(\ys)) = y_i} \\ 
                  & \text{for every } K^\ar \in \Sigma \text{ and } i \in 1..n \\ \\
\end{array}}
\end{array}\]
\caption{A theory of $D_\infty$}\label{fig:prelude}
\end{figure}

It is straightforward again to show the following theorem: 
\begin{theorem}
If $\Sigma |- P$ then $\langle D_{\infty},{\cal I}\rangle \models \Th_\infty$. 
\end{theorem} 

Interestingly, our formalization is not complete -- $D_\infty$ has a complex structure 
and there are many more equalities that one could add to the axiomatization. For instance, 
here are some more axioms that are validated by the denotational model:
\[\begin{array}{l}
    \formula{\forall \oln{x}{n} @.@ app(f_{ptr},\xs) \neq \unr} \\
    \formula{\quad\land\; app(f_{ptr},\xs) \neq \bad} \\
    \formula{\quad\land\; \forall \oln{y}{k} @.@ app(f_{ptr},\xs) \neq K(\ol{y})} \\
    \text{ for every } (f |-> \Lambda\as @.@ \lambda\oln{x{:}\tau}{m} @.@ u) \in P  
    \text{ and } K \in \Sigma \text{ with } m > n
%% \\
%%     \text{ and every } (K{:}\forall\as @.@ \oln{\tau}{k} -> T\;\as) \in \Sigma \text{ and } m > n 
\end{array}\]
These axioms assert that partial applications cannot be equated to 
any constructor, $\bot$ nor $\inj{@BAD@}(1)$. If the reader is worried that without a 
complete formalization of all equalities of $D_\infty$ it is impossible to prove any 
programs correct, we would like to reassure them that that is not the case as we shall
see in the next section.
