Consider this Haskell definition:
\begin{code}
  f xs = head (reverse (True : xs))
  g xs = head (reverse xs)
\end{code}
Both @f@ and @g@ are well typed (and hence do not ``go wrong'' in Milner's sense),
but @g@ can crash (when applied to the empty list), whereas @f@ cannot.
To distinguish the two we need reasoning that goes well beyond 
that embodied in a standard type system.

One response to this challenge is to beef up the type system, a 
path that leads to dependently typed programming.  Another alternative,
studied by many researchers~\cite{contracts-literature}, is to allow 
the programmer to annotate a function with one or more
\emph{contracts}, in addition to its normal type.
For example, we might write the following contract for @reverse@:
\begin{code}
  reverse ::: xs:CF -> { ys | null xs <=> null ys }
\end{code}
This asserts that if @reverse@ is applied to a crash-free (@CF@) argument list @xs@
then the result @ys@ will be empty (@null@) if and only if @xs@ is empty.
Notice that @null@ and @<=>@ are just ordinary Haskell functions, perhaps
written by the programmer, even though they appear inside contracts.
With this in hand we might hope to prove that @f@ satisfies the contract
\begin{code}
  f ::: CF -> CF
\end{code}
But how do we verify that @reverse@ and @f@ satisfy the claimed
contracts? Contracts are often tested dynamically~\cite{finder-felliesen}, but 
our plan here is different: we want to verify contracts \emph{statically} 
and \emph{automatically}. It should be clear that there is a good deal of logical reasoning to do,
and a now-popular approach is to hand off the task to a theorem
prover, a SMT solver or first-order logic prover.
With that in mind, we make the following new contributions:
\begin{itemize}
\item We show how to translate Haskell terms
into First Order Logic (FOL) (Section~\ref{ssect:trans-fol}).  
It may appear surprising that this 
is even possible, since Haskell is a higher order language.  Although
the basic idea of the translation is folklore in the community,
we believe that this paper is the first to explain it explicitly.

\item We also show how to translate \emph{contracts} into FOL
      (Section~\ref{s:contracts-fol}), 
      a translation that is rather less obvious.

\item We give a proof based on denotational semantics 
that if the FOL prover discharges a 
suitable theorem about the translated Haskell term and contract, 
then indeed the original Haskell term satisfies that contract (Section~\ref{s:xxx}).

%\item It is one thing to make a sound translation, and quite another
%to produce FOL terms that the FOL prover can actually prove anything
%about --- a common experience is that it goes out to lunch instead.  We
%describe a number of techniques that dramatically improve
%theorem-proving times, moving them from infeasible to feasible (Section\ref{xxx}).

\item For this paper we focus on the
translation, but we have also implemented a static contract checker
for Haskell itself, by using GHC as a front end.  We have evaluated
the practicality of this approach on many examples, including lazy and
higher-order programs, as we describe in Section~\ref{xxx}.  \spj{I'd like
to say something more substantial here.}
\end{itemize}

Our approach to static contract checking is distinctively different to
previous work: instead of wrapping and symbolic execution we harness
purity and laziness to \emph{directly encode the denotational semantics of programs
and contracts in first-order logic}. It turns that lazy programs (as opposed to
strict programs) have a very natural translation into first-order logic.
We discuss similarities and differences from
related work in Section~\ref{s:related}.


















